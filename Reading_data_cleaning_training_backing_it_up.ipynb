{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraries\n",
    "import urllib.request\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In 1974, the teenager Martha Moxley (Maggie Gr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OK... so... I really like Kris Kristofferson a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>***SPOILER*** Do not read this, if you think a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  In 1974, the teenager Martha Moxley (Maggie Gr...          1\n",
       "1  OK... so... I really like Kris Kristofferson a...          0\n",
       "2  ***SPOILER*** Do not read this, if you think a...          0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading the .csv file from Pandas and examining the first 3 rows\n",
    "# The shape of our data is (50000,2), we have 50K rows with 2 columns of review and sentiment. We are going to define a helper function which will help us in various steps of cleaning the text data such as stopwords removal, lowering the case, etc.\n",
    "df = pd.read_csv('movie_data.csv', encoding='utf-8')\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning the text data\n",
    "# init Objects\n",
    "# In the below function, we are lowering the cases of sentences, breaking them into tokens, preserving the tokens if they are not part of predefined stopwords and finally stemming them for the root form.\n",
    "# Once all the below gets completed we are returning the clean text in the end.\n",
    "tokenizer=RegexpTokenizer(r'\\w+')\n",
    "en_stopwords=set(stopwords.words('english'))\n",
    "ps=PorterStemmer()\n",
    "def getStemmedReview(review):\n",
    "    review=review.lower()\n",
    "    review=review.replace(\"<br /><br />\",\" \")\n",
    "    #Tokenize\n",
    "    tokens=tokenizer.tokenize(review)\n",
    "    new_tokens=[token for token in tokens if token not in  en_stopwords]\n",
    "    stemmed_tokens=[ps.stem(token) for token in new_tokens]\n",
    "    clean_review=' '.join(stemmed_tokens)\n",
    "    return clean_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning all the reviews and splitting our data for training and testing.\n",
    "# As our total length of data is 50K rows, we are splitting it into 35K rows for training and 15K for testing purposes.\n",
    "df['review'].apply(getStemmedReview)\n",
    "X_train = df.loc[:35000, 'review'].values\n",
    "y_train = df.loc[:35000, 'sentiment'].values\n",
    "X_test = df.loc[35000:, 'review'].values\n",
    "y_test = df.loc[35000:, 'sentiment'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming words into feature vectors\n",
    "# To feed the data to the Machine Learning model, we have to convert categorical data, such as text or words, into a numerical form.\n",
    "# We are going to use TfidfVectorizer for this purpose which is already present in the scikit-learn library\n",
    "# we perform the fit operation only on the training set and once the vectorizer learns completely from the training data, we use the same learning to transform our test data.\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(sublinear_tf=True, encoding='utf-8',decode_error='ignore')\n",
    "vectorizer.fit(X_train)\n",
    "X_train=vectorizer.transform(X_train)\n",
    "X_test=vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score on training data is: 0.935973257906917\n",
      "Score on testing data is: 0.8976666666666666\n"
     ]
    }
   ],
   "source": [
    "# Creating the model and checking the score on training and test data\n",
    "# Here we are using the LogisticRegression model because it’s easy to interpret in terms of probability of the output. Feel free to explore other models as per your preference.\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model=LogisticRegression(solver='liblinear')\n",
    "model.fit(X_train,y_train)\n",
    "print(\"Score on training data is: \"+str(model.score(X_train,y_train)))\n",
    "print(\"Score on testing data is: \"+str(model.score(X_test,y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.78833439, 0.21166561]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let’s verify our model’s output on a single review\n",
    "# Below is our test point df.iloc[35000,0], which is same as our first point in testing data i.e. X_test[0]\n",
    "#If you haven't seen the gong show TV series then you won't like this movie much at all, not that knowing the series makes this a great movie. <br /><br />I give it a 5 out of 10 because a few things make it kind of amusing that help make up for its obvious problems.<br />\n",
    "#When we perform prediction on above point we can see below that our model is performing well enough.\n",
    "# Here 0 denotes a negative sentiment\n",
    "model.predict(X_test[0])\n",
    "# 78% probability that the given text is negative\n",
    "model.predict_proba(X_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['vectorizer.pkl']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model deployment\n",
    "# Serializing fitted scikit-learn estimators\n",
    "# Because we don’t want to retrain our model every time the web-application loads we go for the option of model persistence through Python’s in-built pickle module\n",
    "import joblib\n",
    "joblib.dump(en_stopwords,'stopwords.pkl') \n",
    "joblib.dump(model,'model.pkl')\n",
    "joblib.dump(vectorizer,'vectorizer.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
